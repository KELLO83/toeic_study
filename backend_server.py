from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import psycopg2
from psycopg2.extras import RealDictCursor
import sys
from openai import OpenAI
import requests
import json

app = FastAPI()

# Enable CORS so Next.js (port 3000) can call FastAPI (port 8000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB Config
DB_CONFIG = {
    "host": "localhost",
    "port": "5432",
    "database": "toeic",
    "user": "postgres",
    "password": "1234"
}

def get_db_connection():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        print(f"DB Connection Error: {e}")
        return None

@app.get("/")
def read_root():
    return {"message": "TOEIC Whisper Backend is running!"}

@app.get("/words")
def get_words(limit: int = 100):
    conn = get_db_connection()
    if not conn:
        raise HTTPException(status_code=500, detail="Database connection failed")
    
    try:
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("SELECT id, word, meaning, sheet_name FROM toeic_word LIMIT %s", (limit,))
        rows = cur.fetchall()
        cur.close()
        conn.close()
        return rows
    except Exception as e:
        conn.close()
        raise HTTPException(status_code=500, detail=str(e))


# ... (existing imports)
import requests
import json
import edge_tts
from fastapi.responses import StreamingResponse
import io

# ... (existing helper functions)

# TTS Endpoint
@app.get("/tts")
async def text_to_speech(text: str, voice: str = "en-US-ChristopherNeural"):
    """
    Stream TTS audio directly without saving to file.
    Voices:
    - US: en-US-ChristopherNeural (Male), en-US-AnaNeural (Female)
    - UK: en-GB-SoniaNeural (Female), en-GB-RyanNeural (Male)
    - AU: en-AU-NatashaNeural (Female)
    """
    communicate = edge_tts.Communicate(text, voice)
    
    # Create a generator that yields chunks of audio
    async def audio_generator():
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                yield chunk["data"]

    return StreamingResponse(audio_generator(), media_type="audio/mpeg")

def validate_with_llm(word: str, meaning: str):
    url = "http://localhost:11434/api/chat"
    
    # System Prompt for Exaone 3.5 (Korean Optimized)
    system_prompt = """ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì˜ì–´ ë‹¨ì–´ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ 'Word'ì™€ 'Meaning'ì„ ì²˜ë¦¬í•˜ì„¸ìš”.

    [ê·œì¹™]
    1. **Meaningì´ ë¹„ì–´ìˆëŠ” ê²½ìš°**:
       - Wordì˜ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
       - Meaningì—ëŠ” **ì˜¤ì§ í•œêµ­ì–´ ëœ»ë§Œ** 1~2ê°œ ì…ë ¥í•˜ì„¸ìš”. (ì˜ì–´ ì˜ˆì‹œ, ê´„í˜¸ ì„¤ëª… ì ˆëŒ€ ê¸ˆì§€)
       - ì˜ˆ: "publicize" -> "ì•Œë¦¬ë‹¤, í™ë³´í•˜ë‹¤" (O) / "ì•Œë¦¬ë‹¤ (announce)" (X)
       - ìƒíƒœëŠ” 'FIX'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
    
    2. **Meaningì´ ì…ë ¥ëœ ê²½ìš° (ê²€ì¦ ëª¨ë“œ)**:
       - Wordì˜ ì˜¤íƒ€ë¥¼ ì¡ìœ¼ì„¸ìš”.
       - Meaningì´ Wordì˜ ëœ»ìœ¼ë¡œ ì ì ˆí•˜ë‹¤ë©´(ì§€ì—½ì ì´ë¼ë„ ë§ìœ¼ë©´) 'OK'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
       - í‹€ë ¸ë‹¤ë©´ 'FIX'ë¥¼ ë°˜í™˜í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”.

    [ì¶œë ¥ ê²°ê³¼]
    ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
    {
        "status": "OK" ë˜ëŠ” "FIX",
        "corrected_word": "ìˆ˜ì •ëœ ë‹¨ì–´ (ìˆ˜ì • ì—†ìœ¼ë©´ null)",
        "corrected_meaning": "ì±„ì›Œì§„/ìˆ˜ì •ëœ ëœ» (ìˆ˜ì • ì—†ìœ¼ë©´ null)",
        "message": "ì§§ì€ ì„¤ëª…"
    }
    """
    
    user_content = f"Word: {word}\nMeaning: {meaning}"
    
    payload = {
        "model": "exaone3.5", 
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ],
        "format": "json",
        "stream": False,
        "temperature": 0.1
    }
    
    try:
        response = requests.post(url, json=payload)
        if response.status_code == 200:
            return json.loads(response.json()['message']['content'])
        return {"status": "ERROR", "message": "LLM Connection Failed"}
    except Exception as e:
        print(f"LLM Error: {e}")
        return {"status": "ERROR", "message": str(e)}

# Load API Key from secrets.json
SOLAR_API_KEY = ""
try:
    with open("secrets.json", "r") as f:
        secrets = json.load(f)
        SOLAR_API_KEY = secrets.get("SOLAR_API_KEY", "")
except Exception as e:
    print(f"Warning: Could not load secrets.json: {e}")

def validate_with_solar_pro(word: str, meaning: str):
    if not SOLAR_API_KEY or "YOUR_ACTUAL_API_KEY" in SOLAR_API_KEY:
        return {"status": "ERROR", "message": "Backend Error: Add your API Key to secrets.json"}

    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=SOLAR_API_KEY
    )
    
    system_prompt = """ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì˜ì–´ ë‹¨ì–´ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ 'Word'ì™€ 'Meaning'ì„ ì²˜ë¦¬í•˜ì„¸ìš”.

    [ê·œì¹™]
    1. **Meaningì´ ë¹„ì–´ìˆëŠ” ê²½ìš°**:
       - Wordì˜ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.
       - Meaningì—ëŠ” **ì˜¤ì§ í•œêµ­ì–´ ëœ»ë§Œ** 1~2ê°œ ì…ë ¥í•˜ì„¸ìš”. (ì˜ì–´ ì˜ˆì‹œ, ê´„í˜¸ ì„¤ëª… ì ˆëŒ€ ê¸ˆì§€)
       - ì˜ˆ: "publicize" -> "ì•Œë¦¬ë‹¤, í™ë³´í•˜ë‹¤" (O)
       - ìƒíƒœëŠ” 'FIX'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
    
    2. **Meaningì´ ì…ë ¥ëœ ê²½ìš° (ê²€ì¦ ëª¨ë“œ)**:
       - Wordì˜ ì˜¤íƒ€ë¥¼ ì¡ìœ¼ì„¸ìš”.
       - Meaningì´ Wordì˜ ëœ»ìœ¼ë¡œ ì ì ˆí•˜ë‹¤ë©´ 'OK'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
       - í‹€ë ¸ë‹¤ë©´ 'FIX'ë¥¼ ë°˜í™˜í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”.

    [ì¶œë ¥ ê²°ê³¼]
    ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
    {
        "status": "OK" ë˜ëŠ” "FIX",
        "corrected_word": "ìˆ˜ì •ëœ ë‹¨ì–´ (ìˆ˜ì • ì—†ìœ¼ë©´ null)",
        "corrected_meaning": "ì±„ì›Œì§„/ìˆ˜ì •ëœ ëœ» (ìˆ˜ì • ì—†ìœ¼ë©´ null)",
        "message": "ì§§ì€ ì„¤ëª…"
    }
    """
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Word: {word}\nMeaning: {meaning}"}
    ]

    try:
        # First API Call to generate reasoning (although we don't strictly use it for JSON parsing, sticking to user request style)
        response = client.chat.completions.create(
            model="upstage/solar-pro-3:free",
            messages=messages,
            extra_body={"reasoning": {"enabled": True}}
        )
        
        content = response.choices[0].message.content
        
        # Parse JSON from content (Handle potential markdown code blocks)
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
             content = content.split("```")[1].split("```")[0].strip()
            
        return json.loads(content)

    except Exception as e:
        print(f"Solar Pro Error: {e}")
        return {"status": "ERROR", "message": f"Solar Pro Error: {str(e)}"}

class AddWordRequest(BaseModel):
    word: str
    meaning: str
    confirmed: bool = False
    model_type: str = "solar-pro"  # "exaone" or "solar-pro"

class ChatRequest(BaseModel):
    message: str
    history: list = []

@app.post("/chat")
async def chat_with_solar(req: ChatRequest):
    if not SOLAR_API_KEY or "YOUR_ACTUAL_API_KEY" in SOLAR_API_KEY:
        raise HTTPException(status_code=500, detail="Backend Error: Add your API Key to secrets.json")

    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=SOLAR_API_KEY
    )

    messages = [
        {
            "role": "system", 
            "content": "ë‹¹ì‹ ì€ TOEIC Whisperì˜ ì „ë‹´ AI íŠœí„° 'Solar'ì…ë‹ˆë‹¤. í˜„ì¬ ì±„íŒ…ì°½ì€ ë§ˆí¬ë‹¤ìš´(#, * ë“±)ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì´ëª¨ì§€ì™€ ì¤„ë°”ê¿ˆë§Œì„ ì´ìš©í•´ ê°€ë…ì„± ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”. 1. [í•µì‹¬ ìš”ì•½]ì„ ì´ëª¨ì§€ ğŸ“Œì™€ í•¨ê»˜ í•œ ì¤„ë¡œ ê°„ë‹¨íˆ ì ê³  ì¤„ì„ ë°”ê¾¸ì„¸ìš”. 2. ì£¼ìš” ë‚´ìš©ì€ ğŸ’¡ ì´ëª¨ì§€ì™€ í•¨ê»˜ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì§§ê²Œ ì„¤ëª…í•˜ì„¸ìš”. 3. ì˜ˆë¬¸ì€ ğŸ“ ì´ëª¨ì§€ì™€ í•¨ê»˜ ì˜ì–´ ë¬¸ì¥ - í•œê¸€ í•´ì„ ìˆœìœ¼ë¡œ ì ìœ¼ì„¸ìš”. 4. ê° ì„¹ì…˜ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ì„ ë„£ì–´ ê°„ê²©ì„ ë„“ê²Œ ë²Œë¦¬ì„¸ìš”. 5. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(##, **, >, - ë“±)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
        }
    ]
    # Add history
    for msg in req.history:
        messages.append(msg)
    # Add new message
    messages.append({"role": "user", "content": req.message})

    try:
        response = client.chat.completions.create(
            model="upstage/solar-pro-3:free",
            messages=messages,
            extra_body={"reasoning": {"enabled": True}}
        )
        return {"response": response.choices[0].message.content}
    except Exception as e:
        print(f"Chat Error Detail: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AI Error: {str(e)}")

@app.post("/words")
def add_word(req: AddWordRequest):
    conn = get_db_connection()
    if not conn:
        raise HTTPException(status_code=500, detail="Database connection failed")
    
    try:
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # 1. Duplicate Check
        # 1. Duplicate Check
        cur.execute("SELECT id, meaning FROM toeic_word WHERE word = %s", (req.word,))
        existing_word = cur.fetchone()
        if existing_word:
            return {"status": "DUPLICATE", "message": f"'{req.word}'ëŠ” ì´ë¯¸ ë‹¨ì–´ì¥ì— ìˆìŠµë‹ˆë‹¤.\n(ëœ»: {existing_word['meaning']})"}

        # 2. Logic Branch
        if not req.confirmed:
            if req.model_type == "solar-pro":
                # Now using server-side key
                llm_result = validate_with_solar_pro(req.word, req.meaning)
            else:
                 # Default to Local Exaone
                 llm_result = validate_with_llm(req.word, req.meaning)
            
            # Case A: AI suggests fix
            if llm_result.get("status") == "FIX":
                return {
                    "status": "SUGGESTION",
                    "original": req,
                    "suggestion": llm_result
                }
            
            # Case B: AI says OK -> Ask user to confirm
            if llm_result.get("status") == "OK":
                 return {
                    "status": "CONFIRM_NEEDED", 
                    "message": "AI ê²€ì¦ í†µê³¼! ì™„ë²½í•œ ë‹¨ì–´ì…ë‹ˆë‹¤. (ë”ë¸” ì²´í¬)",
                    "original": req
                 }
                 
            return {"status": "ERROR", "message": llm_result.get("message", "AI ê²€ì¦ ì˜¤ë¥˜")}

        # 3. If confirmed=True, INSERT
        cur.execute(
            "INSERT INTO toeic_word (word, meaning, sheet_name) VALUES (%s, %s, %s) RETURNING id",
            (req.word, req.meaning, "User Added")
        )
        new_id = cur.fetchone()['id']
        conn.commit()
        return {"status": "SUCCESS", "id": new_id, "message": "ë‹¨ì–´ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!"}

    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if cur: cur.close()
        if conn: conn.close()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("backend_server:app", host="0.0.0.0", port=8000, reload=True)
